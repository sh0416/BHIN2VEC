{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from math import exp\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rndm(a, b, g, size=1):\n",
    "    \"\"\"Power-law gen for pdf(x) \\propto x^{g-1} for a<=x<=b\"\"\"\n",
    "    r = np.random.random(size=size)\n",
    "    ag, bg = a**g, b**g\n",
    "    return (ag + (bg - ag)*r)**(1./g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.53113, 1.43309, 1.29491, 1.26022, 1.27865, 1.13741, 1.00198,\n",
       "       1.32856, 1.17462, 1.40154])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rndm(1, 2, g=-2, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf(x, a, b, g):\n",
    "    ag, bg = a**g, b**g\n",
    "    return g * x**(g-1) / (bg-ag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3333333333333333,\n",
       " 0.2,\n",
       " 0.14285714285714285,\n",
       " 0.1111111111111111,\n",
       " 0.09090909090909091,\n",
       " 0.07692307692307693,\n",
       " 0.06666666666666667,\n",
       " 0.058823529411764705,\n",
       " 0.05263157894736842,\n",
       " 0.047619047619047616,\n",
       " 0.043478260869565216,\n",
       " 0.04,\n",
       " 0.037037037037037035,\n",
       " 0.034482758620689655,\n",
       " 0.03225806451612903,\n",
       " 0.030303030303030304,\n",
       " 0.02857142857142857,\n",
       " 0.02702702702702703,\n",
       " 0.02564102564102564,\n",
       " 0.024390243902439025,\n",
       " 0.023255813953488372,\n",
       " 0.022222222222222223,\n",
       " 0.02127659574468085,\n",
       " 0.02040816326530612,\n",
       " 0.0196078431372549,\n",
       " 0.018867924528301886,\n",
       " 0.01818181818181818,\n",
       " 0.017543859649122806,\n",
       " 0.01694915254237288,\n",
       " 0.01639344262295082,\n",
       " 0.015873015873015872,\n",
       " 0.015384615384615385,\n",
       " 0.014925373134328358,\n",
       " 0.014492753623188406,\n",
       " 0.014084507042253521,\n",
       " 0.0136986301369863,\n",
       " 0.013333333333333334,\n",
       " 0.012987012987012988,\n",
       " 0.012658227848101266,\n",
       " 0.012345679012345678,\n",
       " 0.012048192771084338,\n",
       " 0.011764705882352941,\n",
       " 0.011494252873563218,\n",
       " 0.011235955056179775,\n",
       " 0.01098901098901099,\n",
       " 0.010752688172043012,\n",
       " 0.010526315789473684,\n",
       " 0.010309278350515464,\n",
       " 0.010101010101010102,\n",
       " 0.009900990099009901,\n",
       " 0.009708737864077669,\n",
       " 0.009523809523809525,\n",
       " 0.009345794392523364,\n",
       " 0.009174311926605505,\n",
       " 0.009009009009009009,\n",
       " 0.008849557522123894,\n",
       " 0.008695652173913044,\n",
       " 0.008547008547008548,\n",
       " 0.008403361344537815,\n",
       " 0.008264462809917356,\n",
       " 0.008130081300813009,\n",
       " 0.008,\n",
       " 0.007874015748031496,\n",
       " 0.007751937984496124,\n",
       " 0.007633587786259542,\n",
       " 0.007518796992481203,\n",
       " 0.007407407407407408,\n",
       " 0.0072992700729927005,\n",
       " 0.007194244604316547,\n",
       " 0.0070921985815602835,\n",
       " 0.006993006993006993,\n",
       " 0.006896551724137931,\n",
       " 0.006802721088435374,\n",
       " 0.006711409395973154,\n",
       " 0.006622516556291391,\n",
       " 0.006535947712418301,\n",
       " 0.0064516129032258064,\n",
       " 0.006369426751592357,\n",
       " 0.006289308176100629,\n",
       " 0.006211180124223602,\n",
       " 0.006134969325153374,\n",
       " 0.006060606060606061,\n",
       " 0.005988023952095809,\n",
       " 0.005917159763313609,\n",
       " 0.005847953216374269,\n",
       " 0.005780346820809248,\n",
       " 0.005714285714285714,\n",
       " 0.005649717514124294,\n",
       " 0.00558659217877095,\n",
       " 0.0055248618784530384,\n",
       " 0.00546448087431694,\n",
       " 0.005405405405405406,\n",
       " 0.0053475935828877,\n",
       " 0.005291005291005291,\n",
       " 0.005235602094240838,\n",
       " 0.0051813471502590676,\n",
       " 0.005128205128205128,\n",
       " 0.005076142131979695,\n",
       " 0.005025125628140704]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pdf(0.5, x, x+1, 2) for x in range(1, 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.bipartite.random_graph(10, 100, p=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeView((0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Graph' object has no attribute 'sets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-1fdc1a805e93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m# put nodes from X at x=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m# put nodes from Y at x=2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Graph' object has no attribute 'sets'"
     ]
    }
   ],
   "source": [
    "X, Y = graph.sets(B)\n",
    "pos = dict()\n",
    "pos.update( (n, (1, i)) for i, n in enumerate(X) ) # put nodes from X at x=1\n",
    "pos.update( (n, (2, i)) for i, n in enumerate(Y) ) # put nodes from Y at x=2\n",
    "nx.draw(B, pos=pos)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthesize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type = np.asarray([10, 100, 100, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00876 0.00878 0.00473 0.00168]\n",
      " [0.00473 0.00635 0.00368 0.00513]\n",
      " [0.00992 0.00225 0.0072  0.0009 ]\n",
      " [0.00217 0.00108 0.00081 0.00983]]\n"
     ]
    }
   ],
   "source": [
    "density = np.random.rand(node_type.shape[0], node_type.shape[0]) / 100\n",
    "print(density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = [[sp.random(x, y, density=d) for y, d in zip(node_type, d_list)] \n",
    "       for x, d_list in zip(node_type, density)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = sp.vstack([sp.hstack(x) for x in adj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = adj.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj[adj!=0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f44e0724f28>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(adj.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007423673246362953"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj.nnz / (adj.shape[0]*adj.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = adj + adj.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj[adj!=0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f44e06791d0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(adj.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014769482958814289"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj.nnz / (adj.shape[0]*adj.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepwalk를 위한 랜덤 워크 함수 GPU 가속화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('preprocess', 'yelp', 'adj.pickle'), 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인접 리스트 데이터, 크기, 시작 인덱스 직렬화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_adj_indice(data):\n",
    "    adj_data = [list(data['adj_indice'][x]) for x in range(data['node_num'])]\n",
    "    adj_size = [len(x) for x in adj_data]\n",
    "    adj_data = [item for sublist in adj_data for item in sublist]\n",
    "    adj_start = [None] * data['node_num']\n",
    "    cnt = 0\n",
    "    for x in range(data['node_num']):\n",
    "        adj_start[x] = cnt\n",
    "        cnt += adj_size[x]\n",
    "    return adj_data, adj_size, adj_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_data, adj_size, adj_start = serialize_adj_indice(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_data = torch.tensor(adj_data, dtype=torch.long)\n",
    "adj_size = torch.tensor(adj_size, dtype=torch.float)\n",
    "adj_start = torch.tensor(adj_start, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랜덤 워크 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepwalk(v, l, adj_data, adj_size, adj_start):\n",
    "    \"\"\"Random walk\n",
    "    \n",
    "    Args:\n",
    "        v (torch.LongTensor): [Batch_size] start index.\n",
    "        l (int): length of random walk.\n",
    "        adj_data (torch.LongTensor): [E] data bank for adjacency list.\n",
    "        adj_size (torch.FloatTensor): [V] degree for each node.\n",
    "        adj_start (torch.LongTensor): [V] start index for each node in `adj_data`.\n",
    "    Returns:\n",
    "        torch.LongTensor [L, B]\n",
    "    \"\"\"\n",
    "    walk = [None] * l\n",
    "    node = v\n",
    "    walk[0] = node\n",
    "\n",
    "    for i in range(1, l):\n",
    "        offset = torch.floor(torch.rand_like(node, dtype=torch.float) * adj_size[node]).long()\n",
    "        idx = adj_start[node] + offset\n",
    "        node = adj_data[idx]\n",
    "        walk[i] = node\n",
    "    return torch.stack(walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time walk = deepwalk(torch.arange(10, dtype=torch.long), 100, adj_data, adj_size, adj_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metapath2vec을 위한 랜덤 워크 GPU 가속화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('preprocess', 'yelp', 'adj_type.pickle'), 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['type_interval']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인접 리스트 데이터, 크기, 시작 인덱스 직렬화 - 타입별로 따로 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_adj_indice(data):\n",
    "    type_order = list(data['type_interval'].keys())\n",
    "    adj_data = [data['adj_indice'][x] for x in range(data['node_num'])]\n",
    "    adj_data = [[list(x[y]) for y in type_order] for x in adj_data]\n",
    "    adj_size = [[len(y) for y in x] for x in adj_data]\n",
    "    adj_start = [[None]*len(type_order) for _ in range(data['node_num'])]\n",
    "    count = 0\n",
    "    for i in range(data['node_num']):\n",
    "        for j in range(len(type_order)):\n",
    "            adj_start[i][j] = count\n",
    "            count += adj_size[i][j]\n",
    "    adj_data = [item for sublist in adj_data for subsublist in sublist for item in subsublist]\n",
    "    return adj_data, adj_size, adj_start, type_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_data, adj_size, adj_start, type_order = serialize_adj_indice(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_data = torch.tensor(adj_data, dtype=torch.long)\n",
    "adj_size = torch.tensor(adj_size, dtype=torch.float)\n",
    "adj_start = torch.tensor(adj_start, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랜덤 워크 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metapathwalk(v, v_t, l, metapath, adj_data, adj_size, adj_start):\n",
    "    \"\"\"Random walk\n",
    "    \n",
    "    Args:\n",
    "        v (torch.LongTensor): [Batch_size] start index.\n",
    "        v_t (torch.LongTensor): [Batch_size] type of start node.\n",
    "        l (int): length of random walk.\n",
    "        metapath (torch.LongTensor)): metapath\n",
    "        adj_data (torch.LongTensor): [E] data bank for adjacency list.\n",
    "        adj_size (torch.FloatTensor): [V] degree for each node.\n",
    "        adj_start (torch.LongTensor): [V] start index for each node in `adj_data`.\n",
    "    Returns:\n",
    "        torch.LongTensor [L, B]\n",
    "    \"\"\"\n",
    "    walk = [None] * l\n",
    "    node = v\n",
    "    metapath_idx = torch.tensor([(metapath==x).nonzero()[0] for x in v_t], dtype=torch.long)\n",
    "    walk[0] = node\n",
    "\n",
    "    for i in range(1, l):\n",
    "        metapath_idx = (metapath_idx + 1) % metapath.shape[0]\n",
    "        adj_size_type = adj_size[node].gather(dim=1, index=metapath[metapath_idx].unsqueeze(1)).squeeze(1)\n",
    "        assert not torch.any(adj_size_type == 0)\n",
    "        \n",
    "        offset = torch.floor(torch.rand_like(node, dtype=torch.float) * adj_size_type).long()\n",
    "        \n",
    "        adj_start_type = adj_start[node].gather(dim=1, index=metapath[metapath_idx].unsqueeze(1)).squeeze(1)\n",
    "        idx = adj_start_type + offset\n",
    "        \n",
    "        node = adj_data[idx]\n",
    "        walk[i] = node\n",
    "    return torch.stack(walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type(v, type_interval_dict, type_order):\n",
    "    for k, interval in type_interval_dict.items():\n",
    "        if interval[0]<= v and v<=interval[1]:\n",
    "            return type_order.index(k)\n",
    "    raise Exception\n",
    "\n",
    "metapath = 'URWRWRBRWRWR'\n",
    "metapath = torch.tensor([type_order.index(x) for x in metapath], dtype=torch.long)\n",
    "\n",
    "node = torch.randint(80000, size=(10,), dtype=torch.long)\n",
    "node_type = [get_type(x, data['type_interval'], type_order) for x in node]\n",
    "\n",
    "walk = metapathwalk(node, node_type, 100, metapath, adj_data, adj_size, adj_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time walk = metapathwalk(node, node_type, 100, metapath, adj_data, adj_size, adj_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JUST를 위한 랜덤 워크 GPU 가속화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type(v, type_interval_dict, type_order):\n",
    "    for k, interval in type_interval_dict.items():\n",
    "        if interval[0]<= v and v<=interval[1]:\n",
    "            return type_order.index(k)\n",
    "    raise Exception\n",
    "    \n",
    "node = torch.randint(80000, size=(10,), dtype=torch.long)\n",
    "node_type = torch.tensor([get_type(x, data['type_interval'], type_order) for x in node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_degree = adj_size[node].sum(dim=1, keepdim=True)\n",
    "homogeneous_degree = adj_size[node].gather(dim=1, index=node_type.unsqueeze(1))\n",
    "heterogeneous_degree = total_degree - homogeneous_degree\n",
    "\n",
    "prob_stay = torch.where(homogeneous_degree==0, torch.tensor(0.0), torch.where(heterogeneous_degree==0, torch.tensor(1.0), torch.tensor(alpha)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stay = torch.bernoulli(prob_stay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homogeneous = torch.zeros_like(adj_size[node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homogeneous.scatter_(dim=1, index=node_type.unsqueeze(1), src=torch.tensor(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heterogeneous = (adj_size[node]>0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "heterogeneous.scatter_(dim=1, index=node_type.unsqueeze(1), src=torch.tensor(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heterogeneous_tmp = heterogeneous.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "que = [deque() for _ in range(node.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(node.shape[0]):\n",
    "    heterogeneous[i, que[i]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heterogeneous[heterogeneous.sum(dim=1)==0] = heterogeneous[heterogeneous.sum(dim=1)==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heterogeneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = homogeneous * (stay) + heterogeneous * (1-stay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_type = torch.multinomial(weight, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "next_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def justwalk(v, v_t, l, alpha, que_size, adj_data, adj_size, adj_start):\n",
    "    \"\"\"Random walk\n",
    "    \n",
    "    Args:\n",
    "        v (torch.LongTensor): [Batch_size] start index.\n",
    "        v_t (torch.LongTensor): [Batch_size] type of start node.\n",
    "        l (int): length of random walk.\n",
    "        alpha (float): stay probability\n",
    "        que_size (int): the size of queue\n",
    "        adj_data (torch.LongTensor): [E] data bank for adjacency list.\n",
    "        adj_size (torch.FloatTensor): [V] degree for each node.\n",
    "        adj_start (torch.LongTensor): [V] start index for each node in `adj_data`.\n",
    "    Returns:\n",
    "        torch.LongTensor [L, B]\n",
    "    \"\"\"\n",
    "    walk = [None] * l\n",
    "    node = v\n",
    "    node_type = v_t\n",
    "    walk[0] = node\n",
    "    que = [deque() for _ in v.shape[0]]\n",
    "    stay_l = [1 for _ in v.shape[0]]\n",
    "    \n",
    "    for i in range(1, l):\n",
    "        total_degree = adj_size[node].sum(dim=1, keepdim=True)\n",
    "        homogeneous_degree = adj_size[node].gather(dim=1, index=node_type.unsqueeze(1))\n",
    "        heterogeneous_degree = total_degree - homogeneous_degree\n",
    "\n",
    "        prob_stay = torch.where(homogeneous_degree==0, \n",
    "                                torch.tensor(0.0), \n",
    "                                torch.where(heterogeneous_degree==0, \n",
    "                                            torch.tensor(1.0), \n",
    "                                            torch.tensor(alpha ** stay_l)))\n",
    "        stay = torch.bernoulli(prob_stay)\n",
    "        \n",
    "        homogeneous = torch.zeros_like(adj_size[node])\n",
    "        homogeneous.scatter_(dim=1, index=node_type.unsqueeze(1), src=torch.tensor(1))\n",
    "        \n",
    "        heterogeneous = (adj_size[node]>0).float()\n",
    "        heterogeneous.scatter_(dim=1, index=node_type.unsqueeze(1), src=torch.tensor(0))\n",
    "        heterogeneous_tmp = heterogeneous.clone().detach()\n",
    "        for i in range(node.shape[0]):\n",
    "            heterogeneous[i, que[i]] = 0\n",
    "        heterogeneous[heterogeneous.sum(dim=1)==0] = heterogeneous_tmp[heterogeneous.sum(dim=1)==0]\n",
    "        \n",
    "        weight = homogeneous * (stay) + heterogeneous * (1-stay)\n",
    "        node_type = torch.multinomial(weight, 1).squeeze(1)\n",
    "        \n",
    "        for i in range(node.shape[0]):\n",
    "            if stay\n",
    "        adj_size_type = adj_size[node].gather(dim=1, index=node_type.unsqueeze(1)).squeeze(1)\n",
    "        assert not torch.any(adj_size_type == 0)\n",
    "        \n",
    "        offset = torch.floor(torch.rand_like(node, dtype=torch.float) * adj_size_type).long()\n",
    "        \n",
    "        adj_start_type = adj_start[node].gather(dim=1, index=node_type.unsqueeze(1)).squeeze(1)\n",
    "        idx = adj_start_type + offset\n",
    "        \n",
    "        node = adj_data[idx]\n",
    "        walk[i] = node\n",
    "    return torch.stack(walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.where(adj_size[node].gather(dim=1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(alpha**2) * (adj_size[node]>0).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanced2vec을 위한 랜덤 워크 GPU 가속화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randint(1, 3, size=(4, 4)).float()\n",
    "node = torch.randint(80000, size=(10,), dtype=torch.long)\n",
    "node_type = torch.tensor([get_type(x, data['type_interval'], type_order) for x in node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_matrix = torch.zeros(10, len(type_order), len(type_order))\n",
    "go_vector = torch.zeros(10, len(type_order))\n",
    "back_vector = torch.zeros(10, len(type_order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "node_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1번 행동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = back_vector.scatter_(dim=1, index=node_type.unsqueeze(1), src=torch.tensor(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2번 행동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type_stack = torch.stack([node_type]*len(type_order)).t().unsqueeze(2)\n",
    "back_vector += context_matrix.gather(dim=2, index=node_type_stack).squeeze(2)\n",
    "_ = context_matrix.scatter_(dim=2, index=node_type_stack, src=torch.tensor(0))\n",
    "_ = go_vector.scatter_(dim=1, index=node_type.unsqueeze(1), src=torch.tensor(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3번 행동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type_stack = torch.stack([node_type]*len(type_order)).t().unsqueeze(1)\n",
    "src = torch.stack([A]*10).gather(dim=1, index=node_type_stack)\n",
    "_ = context_matrix.scatter_add_(dim=1, index=node_type_stack, src=src)\n",
    "go_vector += src.squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4번 행동 및 샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = go_vector + back_vector\n",
    "weight = weight * (adj_size[node] > 0).float()\n",
    "next_type = torch.multinomial(weight, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancewalk(v, v_t, l, A, t, adj_data, adj_size, adj_start):\n",
    "    \"\"\"Random walk\n",
    "    \n",
    "    Args:\n",
    "        v (torch.LongTensor): [Batch_size] start index.\n",
    "        v_t (torch.LongTensor): [Batch_size] type of start node.\n",
    "        l (int): length of random walk.\n",
    "        A (torch.FloatTensor)): [T, T] inverse training rate matrix.\n",
    "        t (int): number of type\n",
    "        adj_data (torch.LongTensor): [E] data bank for adjacency list.\n",
    "        adj_size (torch.FloatTensor): [V] degree for each node.\n",
    "        adj_start (torch.LongTensor): [V] start index for each node in `adj_data`.\n",
    "    Returns:\n",
    "        torch.LongTensor [L, B]\n",
    "    \"\"\"\n",
    "    walk = [None] * l\n",
    "    node = v\n",
    "    node_type = v_t\n",
    "    walk[0] = node\n",
    "    \n",
    "    # Initialize data structure\n",
    "    context_matrix = torch.zeros(v.shape[0], t, t)\n",
    "    go_vector = torch.zeros(v.shape[0], t)\n",
    "    back_vector = torch.zeros(v.shape[0], t)\n",
    "\n",
    "    for i in range(1, l):\n",
    "        # Process 1\n",
    "        back_vector.scatter_(dim=1, index=node_type.unsqueeze(1), src=torch.tensor(0))\n",
    "        \n",
    "        node_type_stack = torch.stack([node_type]*len(type_order)).t()\n",
    "        \n",
    "        # Process 2\n",
    "        back_vector += context_matrix.gather(dim=2, index=node_type_stack.unsqueeze(2)).squeeze(2)\n",
    "        context_matrix.scatter_(dim=2, index=node_type_stack.unsqueeze(2), src=torch.tensor(0))\n",
    "        go_vector.scatter_(dim=1, index=node_type.unsqueeze(1), src=torch.tensor(0))\n",
    "        \n",
    "        # Process 3\n",
    "        src = torch.stack([A]*v.shape[0]).gather(dim=1, index=node_type_stack.unsqueeze(1))\n",
    "        context_matrix.scatter_add_(dim=1, index=node_type_stack.unsqueeze(1), src=src)\n",
    "        go_vector += src.squeeze(1)\n",
    "        \n",
    "        # Process 4\n",
    "        weight = go_vector + back_vector\n",
    "        np.set_printoptions(precision=10000, suppress=False)\n",
    "        weight = weight * (adj_size[node] > 0).float()\n",
    "        node_type = torch.multinomial(weight, 1).squeeze(1)\n",
    "        \n",
    "        adj_size_type = adj_size[node].gather(dim=1, index=node_type.unsqueeze(1)).squeeze(1)\n",
    "        assert not torch.any(adj_size_type == 0)\n",
    "        \n",
    "        offset = torch.floor(torch.rand_like(node, dtype=torch.float) * adj_size_type).long()\n",
    "        \n",
    "        adj_start_type = adj_start[node].gather(dim=1, index=node_type.unsqueeze(1)).squeeze(1)\n",
    "        idx = adj_start_type + offset\n",
    "        \n",
    "        node = adj_data[idx]\n",
    "        walk[i] = node\n",
    "    return torch.stack(walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type(v, type_interval_dict, type_order):\n",
    "    for k, interval in type_interval_dict.items():\n",
    "        if interval[0]<= v and v<=interval[1]:\n",
    "            return type_order.index(k)\n",
    "    raise Exception\n",
    "\n",
    "#A = torch.randint(1, 3, size=(4, 4)).float()\n",
    "A = torch.tensor([[1, 10000, 1, 1], [10000, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]).float()\n",
    "node = torch.randint(80000, size=(1,), dtype=torch.long)\n",
    "node_type = torch.tensor([get_type(x, data['type_interval'], type_order) for x in node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.5 ms ± 1.95 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit walk = balancewalk(node, node_type, 100, A, len(type_order), adj_data, adj_size, adj_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk = balancewalk(node, node_type, 100, A, len(type_order), adj_data, adj_size, adj_start)\n",
    "print((torch.tensor([[get_type(x, data['type_interval'], type_order) for x in b] for b in walk])==0).nonzero().shape[0],\n",
    "(torch.tensor([[get_type(x, data['type_interval'], type_order) for x in b] for b in walk])==1).nonzero().shape[0],\n",
    "(torch.tensor([[get_type(x, data['type_interval'], type_order) for x in b] for b in walk])==2).nonzero().shape[0],\n",
    "(torch.tensor([[get_type(x, data['type_interval'], type_order) for x in b] for b in walk])==3).nonzero().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([[get_type(x, data['type_interval'], type_order) for x in b] for b in walk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['class']['T'] = np.full(data['type_interval']['T'][1]-data['type_interval']['T'][0]+1, fill_value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = np.concatenate((data['class']['A'], data['class']['T'], data['class']['V'], data['class']['P']), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_list(walk, key):\n",
    "    walk = [x for x in walk if data['type_interval'][key][0]<=x and x<=data['type_interval'][key][1]]\n",
    "    return [class_dict[x] for x in walk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_class_list(walk, 'V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_str_dict = {x: i for i, x in enumerate(data['type_interval'].keys())}\n",
    "type_str_inverse_dict = {i: x for x, i in type_str_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_type_mask = torch.zeros(len(data['adj_indice'].keys()), 4)\n",
    "for k, v in data['adj_indice'].items():\n",
    "    for k2 in v.keys():\n",
    "        possible_type_mask[k, type_str_dict[k2]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacent_node_num_per_type = torch.zeros(data['node_num'], 4, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in data['adj_indice'].items():\n",
    "    for k2, v2 in v.items():\n",
    "        adjacent_node_num_per_type[k, type_str_dict[k2]] = len(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacent_node_num_per_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = torch.zeros(data['node_num'], 4, dtype=torch.long)\n",
    "tmp = torch.zeros(4, dtype=torch.long)\n",
    "for i in range(data['node_num']):\n",
    "    start_idx[i, :] = tmp\n",
    "    tmp += adjacent_node_num_per_type[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_adj = [None] * 4\n",
    "for type_k, type_idx in type_str_dict.items():\n",
    "    packed_adj[type_idx] = [None] * data['node_num']\n",
    "    for k, v in data['adj_indice'].items():\n",
    "        packed_adj[type_idx][k] = torch.tensor(list(v[type_k]) if v.get(type_k) is not None else [], dtype=torch.long)\n",
    "    packed_adj[type_idx] = torch.cat(packed_adj[type_idx], dim=0)\n",
    "pad_packed_adj = nn.utils.rnn.pad_sequence(packed_adj)\n",
    "print(pad_packed_adj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get(pad_packed_adj, start_idx, adjacent_node_num_per_type, node, idx, type_):\n",
    "    return pad_packed_adj[start_idx[node, type_]+idx, type_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get(pad_packed_adj, \n",
    "    start_idx, \n",
    "    adjacent_node_num_per_type, \n",
    "    torch.tensor([19999, 20000], dtype=torch.long), \n",
    "    torch.tensor([0, 0], dtype=torch.long), \n",
    "    torch.tensor([3, 1], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_attention = torch.from_numpy(np.asarray([[1, 1, 1, 1], [1, 1, 1, 1], [100, 1, 1, 1], [1, 1, 1, 1]])).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_packed_adj = pad_packed_adj.cuda()\n",
    "start_idx = start_idx.cuda()\n",
    "adjacent_node_num_per_type = adjacent_node_num_per_type.cuda()\n",
    "possible_type_mask = possible_type_mask.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class BalancedWalkFactory(object):\n",
    "    def __init__(self,\n",
    "                 possible_type_mask,\n",
    "                 adjacent_node_num_per_type,\n",
    "                 start_idx,\n",
    "                 pad_packed_adj,\n",
    "                 type_attention,\n",
    "                 type_str_dict):\n",
    "        self.possible_type_mask = possible_type_mask\n",
    "        self.adjacent_node_num_per_type = adjacent_node_num_per_type\n",
    "        self.start_idx = start_idx\n",
    "        self.pad_packed_adj = pad_packed_adj\n",
    "        self.type_attention = type_attention\n",
    "        self.type_str_dict = type_str_dict\n",
    "    \n",
    "    def to(self, device):\n",
    "        self.possible_type_mask = self.possible_type_mask.to(device)\n",
    "        self.adjacent_node_num_per_type = self.adjacent_node_num_per_type.to(device)\n",
    "        self.start_idx = self.start_idx.to(device)\n",
    "        self.pad_packed_adj = self.pad_packed_adj.to(device)\n",
    "        self.type_attention = self.type_attention.to(device)\n",
    "        return self\n",
    "        \n",
    "    def __call__(self, v, l):\n",
    "        batch_size = v.shape[0]\n",
    "        walk = v.new_zeros(l, batch_size, dtype=torch.long)\n",
    "        walk[0, :] = v\n",
    "\n",
    "        history = v.new_zeros(l, batch_size, 4, dtype=torch.long)\n",
    "        return_history = v.new_full((l, batch_size), fill_value=-1, dtype=torch.long)\n",
    "        to_prob = v.new_zeros(batch_size, 4, dtype=torch.long)\n",
    "\n",
    "        cur_type = v.new_tensor([self.type_str_dict[get_type(x, data['type_interval'])] for x in walk[0, :]], dtype=torch.long)\n",
    "\n",
    "        for i in range(1, l):\n",
    "            history[i-1, :, :] = type_attention[cur_type]\n",
    "            return_history[i-1, :] = cur_type\n",
    "            prob = history.sum(dim=0)\n",
    "            prob += to_prob\n",
    "            prob *= possible_type_mask[walk[i-1,:]].long()\n",
    "    \n",
    "            nxt_type = torch.multinomial(prob.float(), 1)\n",
    "            idx = torch.rand(batch_size).cuda()\n",
    "            size = torch.gather(adjacent_node_num_per_type[walk[i-1,:]], 1, nxt_type).squeeze()\n",
    "    \n",
    "            idx = torch.floor(idx * size.float()).long()\n",
    "    \n",
    "            walk[i, :] = get(pad_packed_adj, \n",
    "                             start_idx, \n",
    "                             adjacent_node_num_per_type, \n",
    "                             walk[i-1, :], \n",
    "                             idx, \n",
    "                             nxt_type.squeeze())\n",
    "            cur_type = nxt_type.squeeze()\n",
    "        \n",
    "            to_prob.scatter_(dim=1, index=nxt_type, src=torch.tensor(0))\n",
    "            for j in range(i):\n",
    "                to_prob.scatter_add_(dim=1, index=return_history[[j], :].t(), \n",
    "                                 src=torch.gather(history[j, :, :], dim=1, index=nxt_type))\n",
    "                history[j, :, :].scatter_(dim=1, index=nxt_type, src=torch.tensor(0))\n",
    "        return walk\n",
    "\n",
    "balanced_walk = BalancedWalkFactory(possible_type_mask,\n",
    "                                    adjacent_node_num_per_type,\n",
    "                                    start_idx,\n",
    "                                    pad_packed_adj,\n",
    "                                    torch.from_numpy(np.asarray([[1, 1, 1, 1], [1, 1, 1, 1], [100, 1, 1, 1], [1, 1, 1, 1]])),\n",
    "                                    type_str_dict)\n",
    "balanced_walk = balanced_walk.to(torch.device(\"cuda:0\"))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(5):\n",
    "    walk = balanced_walk(torch.arange(0, 100, 1).cuda(), 80)\n",
    "\n",
    "print('--- %s seconds ---' % (time.time() - start_time))\n",
    "print(walk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_walk(v, adj, type_interval, type_str_dict, type_str_inverse_dict, type_, l): \n",
    "    walk = [v] * l \n",
    "    from_que = deque()\n",
    "    to_prob = np.asarray([0] * 4)\n",
    "    for i in range(1, l): \n",
    "        cur_type = type_str_dict[get_type(walk[i-1], type_interval)]\n",
    "        possible_type = list(map(type_str_dict.get, adj[walk[i-1]].keys()))\n",
    "\n",
    "        # From que update\n",
    "        from_que.append((cur_type, np.copy(type_[cur_type])))\n",
    "\n",
    "        # Calculate probability\n",
    "        prob = np.asarray([0] * 4, dtype=np.float32)\n",
    "        for _, p in from_que:\n",
    "            prob += p\n",
    "        prob += to_prob\n",
    "\n",
    "        nxt_type = np.random.choice(possible_type, 1, p=prob[possible_type]/prob[possible_type].sum())[0]\n",
    "        walk[i] = np.random.choice(list(adj[walk[i-1]][type_str_inverse_dict[nxt_type]]), 1)[0]\n",
    "\n",
    "        # To prob update\n",
    "        to_prob[nxt_type] = 0 \n",
    "        for return_type, p in from_que:\n",
    "            to_prob[return_type] += p[nxt_type]\n",
    "            p[nxt_type] = 0 \n",
    "\n",
    "        while len(from_que) > 0:\n",
    "            if np.all(from_que[0]==0):\n",
    "                from_que.popleft()\n",
    "            else:\n",
    "                break\n",
    "    return walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk = walk.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df_list = []\n",
    "\n",
    "for i in range(1000):\n",
    "    walk = balanced_walk(1, \n",
    "                     data['adj_indice'], \n",
    "                     data['type_interval'], \n",
    "                     type_str_dict,\n",
    "                         type_str_inverse_dict,\n",
    "                     np.asarray([[1, 1, 1, 1], [1, 1, 1, 1], [100, 1, 1, 1], [1, 1, 1, 1]]), \n",
    "                     40)\n",
    "    df = pd.DataFrame({'walk': walk, 'class': [class_dict[x] for x in walk], 'type': [get_type(x, data['type_interval']) for x in walk]})\n",
    "    count_df_list.append(df.groupby('type').count())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#walk = walk[:, 0].cpu().numpy()\n",
    "df = pd.DataFrame({'walk': walk, 'class': [class_dict[x] for x in walk], 'type': [get_type(x, data['type_interval']) for x in walk]})\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df_list = []\n",
    "count_df_list.append(df.groupby('type').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(count_df_list).groupby('type').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['type']=='P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
