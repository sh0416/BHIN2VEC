{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepwalk를 위한 랜덤 워크 함수 GPU 가속화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('preprocess', 'yelp', 'adj.pickle'), 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인접 리스트 데이터, 크기, 시작 인덱스 직렬화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_adj_indice(data):\n",
    "    adj_data = [list(data['adj_indice'][x]) for x in range(data['node_num'])]\n",
    "    adj_size = [len(x) for x in adj_data]\n",
    "    adj_data = [item for sublist in adj_data for item in sublist]\n",
    "    adj_start = [None] * data['node_num']\n",
    "    cnt = 0\n",
    "    for x in range(data['node_num']):\n",
    "        adj_start[x] = cnt\n",
    "        cnt += adj_size[x]\n",
    "    return adj_data, adj_size, adj_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_data, adj_size, adj_start = serialize_adj_indice(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_data = torch.tensor(adj_data, dtype=torch.long)\n",
    "adj_size = torch.tensor(adj_size, dtype=torch.float)\n",
    "adj_start = torch.tensor(adj_start, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랜덤 워크 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepwalk(v, l, adj_data, adj_size, adj_start):\n",
    "    \"\"\"Random walk\n",
    "    \n",
    "    Args:\n",
    "        v (torch.LongTensor): [Batch_size] start index.\n",
    "        l (int): length of random walk.\n",
    "        adj_data (torch.LongTensor): [E] data bank for adjacency list.\n",
    "        adj_size (torch.FloatTensor): [V] degree for each node.\n",
    "        adj_start (torch.LongTensor): [V] start index for each node in `adj_data`.\n",
    "    Returns:\n",
    "        torch.LongTensor [L, B]\n",
    "    \"\"\"\n",
    "    walk = [None] * l\n",
    "    node = v\n",
    "    walk[0] = node\n",
    "\n",
    "    for i in range(1, l):\n",
    "        offset = torch.floor(torch.rand_like(node, dtype=torch.float) * adj_size[node]).long()\n",
    "        idx = adj_start[node] + offset\n",
    "        node = adj_data[idx]\n",
    "        walk[i] = node\n",
    "    return torch.stack(walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time walk = deepwalk(torch.arange(10, dtype=torch.long), 100, adj_data, adj_size, adj_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metapath2vec을 위한 랜덤 워크 GPU 가속화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('preprocess', 'yelp', 'adj_type.pickle'), 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'U': (0, 3679), 'B': (3680, 12428), 'R': (12429, 70361), 'W': (70362, 86701)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['type_interval']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인접 리스트 데이터, 크기, 시작 인덱스 직렬화 - 타입별로 따로 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_adj_indice(data):\n",
    "    type_order = list(data['type_interval'].keys())\n",
    "    adj_data = [data['adj_indice'][x] for x in range(data['node_num'])]\n",
    "    adj_data = [[list(x[y]) for y in type_order] for x in adj_data]\n",
    "    adj_size = [[len(y) for y in x] for x in adj_data]\n",
    "    adj_start = [[None]*len(type_order) for _ in range(data['node_num'])]\n",
    "    count = 0\n",
    "    for i in range(data['node_num']):\n",
    "        for j in range(len(type_order)):\n",
    "            adj_start[i][j] = count\n",
    "            count += adj_size[i][j]\n",
    "    adj_data = [item for sublist in adj_data for subsublist in sublist for item in subsublist]\n",
    "    return adj_data, adj_size, adj_start, type_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_data, adj_size, adj_start, type_order = serialize_adj_indice(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_data = torch.tensor(adj_data, dtype=torch.long)\n",
    "adj_size = torch.tensor(adj_size, dtype=torch.float)\n",
    "adj_start = torch.tensor(adj_start, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랜덤 워크 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metapathwalk(v, v_t, l, metapath, adj_data, adj_size, adj_start):\n",
    "    \"\"\"Random walk\n",
    "    \n",
    "    Args:\n",
    "        v (torch.LongTensor): [Batch_size] start index.\n",
    "        v_t (torch.LongTensor): [Batch_size] type of start node.\n",
    "        l (int): length of random walk.\n",
    "        metapath (torch.LongTensor)): metapath\n",
    "        adj_data (torch.LongTensor): [E] data bank for adjacency list.\n",
    "        adj_size (torch.FloatTensor): [V] degree for each node.\n",
    "        adj_start (torch.LongTensor): [V] start index for each node in `adj_data`.\n",
    "    Returns:\n",
    "        torch.LongTensor [L, B]\n",
    "    \"\"\"\n",
    "    walk = [None] * l\n",
    "    node = v\n",
    "    metapath_idx = torch.tensor([(metapath==x).nonzero()[0] for x in v_t], dtype=torch.long)\n",
    "    walk[0] = node\n",
    "\n",
    "    for i in range(1, l):\n",
    "        metapath_idx = (metapath_idx + 1) % metapath.shape[0]\n",
    "        adj_size_type = adj_size[node].gather(dim=1, index=metapath[metapath_idx].unsqueeze(1)).squeeze(1)\n",
    "        assert not torch.any(adj_size_type == 0)\n",
    "        \n",
    "        offset = torch.floor(torch.rand_like(node, dtype=torch.float) * adj_size_type).long()\n",
    "        \n",
    "        adj_start_type = adj_start[node].gather(dim=1, index=metapath[metapath_idx].unsqueeze(1)).squeeze(1)\n",
    "        idx = adj_start_type + offset\n",
    "        \n",
    "        node = adj_data[idx]\n",
    "        walk[i] = node\n",
    "    return torch.stack(walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type(v, type_interval_dict, type_order):\n",
    "    for k, interval in type_interval_dict.items():\n",
    "        if interval[0]<= v and v<=interval[1]:\n",
    "            return type_order.index(k)\n",
    "    raise Exception\n",
    "\n",
    "metapath = 'URWRWRBRWRWR'\n",
    "metapath = torch.tensor([type_order.index(x) for x in metapath], dtype=torch.long)\n",
    "\n",
    "node = torch.randint(80000, size=(10,), dtype=torch.long)\n",
    "node_type = [get_type(x, data['type_interval'], type_order) for x in node]\n",
    "\n",
    "walk = metapathwalk(node, node_type, 100, metapath, adj_data, adj_size, adj_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time walk = metapathwalk(node, node_type, 100, metapath, adj_data, adj_size, adj_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JUST를 위한 랜덤 워크 GPU 가속화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type(v, type_interval_dict, type_order):\n",
    "    for k, interval in type_interval_dict.items():\n",
    "        if interval[0]<= v and v<=interval[1]:\n",
    "            return type_order.index(k)\n",
    "    raise Exception\n",
    "    \n",
    "node = torch.randint(80000, size=(10,), dtype=torch.long)\n",
    "node_type = torch.tensor([get_type(x, data['type_interval'], type_order) for x in node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_degree = adj_size[node].sum(dim=1, keepdim=True)\n",
    "homogeneous_degree = adj_size[node].gather(dim=1, index=node_type.unsqueeze(1))\n",
    "heterogeneous_degree = total_degree - homogeneous_degree\n",
    "\n",
    "prob_stay = torch.where(homogeneous_degree==0, torch.tensor(0.0), torch.where(heterogeneous_degree==0, torch.tensor(1.0), torch.tensor(alpha)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stay = torch.bernoulli(prob_stay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "homogeneous = torch.zeros_like(adj_size[node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homogeneous.scatter_(dim=1, index=node_type.unsqueeze(1), src=torch.tensor(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "heterogeneous = (adj_size[node]>0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 1.],\n",
       "        [1., 1., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 1., 0., 1.],\n",
       "        [1., 1., 0., 1.],\n",
       "        [1., 1., 0., 1.],\n",
       "        [1., 1., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 1., 0., 1.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heterogeneous.scatter_(dim=1, index=node_type.unsqueeze(1), src=torch.tensor(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "heterogeneous_tmp = heterogeneous.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "que = [deque() for _ in range(node.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(node.shape[0]):\n",
    "    heterogeneous[i, que[i]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "heterogeneous[heterogeneous.sum(dim=1)==0] = heterogeneous[heterogeneous.sum(dim=1)==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 1.],\n",
       "        [1., 1., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 1., 0., 1.],\n",
       "        [1., 1., 0., 1.],\n",
       "        [1., 1., 0., 1.],\n",
       "        [1., 1., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 1., 0., 1.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heterogeneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = homogeneous * (stay) + heterogeneous * (1-stay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_type = torch.multinomial(weight, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [3],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [0],\n",
       "        [3],\n",
       "        [1],\n",
       "        [2],\n",
       "        [1]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def justwalk(v, v_t, l, alpha, que_size, adj_data, adj_size, adj_start):\n",
    "    \"\"\"Random walk\n",
    "    \n",
    "    Args:\n",
    "        v (torch.LongTensor): [Batch_size] start index.\n",
    "        v_t (torch.LongTensor): [Batch_size] type of start node.\n",
    "        l (int): length of random walk.\n",
    "        alpha (float): stay probability\n",
    "        que_size (int): the size of queue\n",
    "        adj_data (torch.LongTensor): [E] data bank for adjacency list.\n",
    "        adj_size (torch.FloatTensor): [V] degree for each node.\n",
    "        adj_start (torch.LongTensor): [V] start index for each node in `adj_data`.\n",
    "    Returns:\n",
    "        torch.LongTensor [L, B]\n",
    "    \"\"\"\n",
    "    walk = [None] * l\n",
    "    node = v\n",
    "    node_type = v_t\n",
    "    walk[0] = node\n",
    "    que = [deque() for _ in v.shape[0]]\n",
    "    stay_l = [1 for _ in v.shape[0]]\n",
    "    \n",
    "    for i in range(1, l):\n",
    "        total_degree = adj_size[node].sum(dim=1, keepdim=True)\n",
    "        homogeneous_degree = adj_size[node].gather(dim=1, index=node_type.unsqueeze(1))\n",
    "        heterogeneous_degree = total_degree - homogeneous_degree\n",
    "\n",
    "        prob_stay = torch.where(homogeneous_degree==0, \n",
    "                                torch.tensor(0.0), \n",
    "                                torch.where(heterogeneous_degree==0, \n",
    "                                            torch.tensor(1.0), \n",
    "                                            torch.tensor(alpha ** stay_l)))\n",
    "        stay = torch.bernoulli(prob_stay)\n",
    "        \n",
    "        homogeneous = torch.zeros_like(adj_size[node])\n",
    "        homogeneous.scatter_(dim=1, index=node_type.unsqueeze(1), src=torch.tensor(1))\n",
    "        \n",
    "        heterogeneous = (adj_size[node]>0).float()\n",
    "        heterogeneous.scatter_(dim=1, index=node_type.unsqueeze(1), src=torch.tensor(0))\n",
    "        heterogeneous_tmp = heterogeneous.clone().detach()\n",
    "        for i in range(node.shape[0]):\n",
    "            heterogeneous[i, que[i]] = 0\n",
    "        heterogeneous[heterogeneous.sum(dim=1)==0] = heterogeneous_tmp[heterogeneous.sum(dim=1)==0]\n",
    "        \n",
    "        weight = homogeneous * (stay) + heterogeneous * (1-stay)\n",
    "        node_type = torch.multinomial(weight, 1).squeeze(1)\n",
    "        \n",
    "        for i in range(node.shape[0]):\n",
    "            if stay\n",
    "        adj_size_type = adj_size[node].gather(dim=1, index=node_type.unsqueeze(1)).squeeze(1)\n",
    "        assert not torch.any(adj_size_type == 0)\n",
    "        \n",
    "        offset = torch.floor(torch.rand_like(node, dtype=torch.float) * adj_size_type).long()\n",
    "        \n",
    "        adj_start_type = adj_start[node].gather(dim=1, index=node_type.unsqueeze(1)).squeeze(1)\n",
    "        idx = adj_start_type + offset\n",
    "        \n",
    "        node = adj_data[idx]\n",
    "        walk[i] = node\n",
    "    return torch.stack(walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.where(adj_size[node].gather(dim=1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2500, 0.2500, 0.0000, 0.2500],\n",
       "        [0.2500, 0.2500, 0.0000, 0.2500],\n",
       "        [0.0000, 0.0000, 0.2500, 0.0000],\n",
       "        [0.2500, 0.2500, 0.0000, 0.2500],\n",
       "        [0.0000, 0.0000, 0.2500, 0.0000],\n",
       "        [0.2500, 0.2500, 0.0000, 0.2500],\n",
       "        [0.2500, 0.2500, 0.0000, 0.2500],\n",
       "        [0.0000, 0.0000, 0.2500, 0.0000],\n",
       "        [0.2500, 0.2500, 0.0000, 0.2500],\n",
       "        [0.2500, 0.2500, 0.0000, 0.2500]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(alpha**2) * (adj_size[node]>0).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanced2vec을 위한 랜덤 워크 GPU 가속화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randint(1, 3, size=(4, 4)).float()\n",
    "node = torch.randint(80000, size=(10,), dtype=torch.long)\n",
    "node_type = torch.tensor([get_type(x, data['type_interval'], type_order) for x in node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_matrix = torch.zeros(10, len(type_order), len(type_order))\n",
    "go_vector = torch.zeros(10, len(type_order))\n",
    "back_vector = torch.zeros(10, len(type_order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "node_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1번 행동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = back_vector.scatter_(dim=1, index=node_type.unsqueeze(1), src=torch.tensor(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2번 행동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type_stack = torch.stack([node_type]*len(type_order)).t().unsqueeze(2)\n",
    "back_vector += context_matrix.gather(dim=2, index=node_type_stack).squeeze(2)\n",
    "_ = context_matrix.scatter_(dim=2, index=node_type_stack, src=torch.tensor(0))\n",
    "_ = go_vector.scatter_(dim=1, index=node_type.unsqueeze(1), src=torch.tensor(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3번 행동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type_stack = torch.stack([node_type]*len(type_order)).t().unsqueeze(1)\n",
    "src = torch.stack([A]*10).gather(dim=1, index=node_type_stack)\n",
    "_ = context_matrix.scatter_add_(dim=1, index=node_type_stack, src=src)\n",
    "go_vector += src.squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4번 행동 및 샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = go_vector + back_vector\n",
    "weight = weight * (adj_size[node] > 0).float()\n",
    "next_type = torch.multinomial(weight, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancewalk(v, v_t, l, A, t, adj_data, adj_size, adj_start):\n",
    "    \"\"\"Random walk\n",
    "    \n",
    "    Args:\n",
    "        v (torch.LongTensor): [Batch_size] start index.\n",
    "        v_t (torch.LongTensor): [Batch_size] type of start node.\n",
    "        l (int): length of random walk.\n",
    "        A (torch.FloatTensor)): [T, T] inverse training rate matrix.\n",
    "        t (int): number of type\n",
    "        adj_data (torch.LongTensor): [E] data bank for adjacency list.\n",
    "        adj_size (torch.FloatTensor): [V] degree for each node.\n",
    "        adj_start (torch.LongTensor): [V] start index for each node in `adj_data`.\n",
    "    Returns:\n",
    "        torch.LongTensor [L, B]\n",
    "    \"\"\"\n",
    "    walk = [None] * l\n",
    "    node = v\n",
    "    node_type = v_t\n",
    "    walk[0] = node\n",
    "    \n",
    "    # Initialize data structure\n",
    "    context_matrix = torch.zeros(v.shape[0], t, t)\n",
    "    go_vector = torch.zeros(v.shape[0], t)\n",
    "    back_vector = torch.zeros(v.shape[0], t)\n",
    "\n",
    "    for i in range(1, l):\n",
    "        # Process 1\n",
    "        back_vector.scatter_(dim=1, index=node_type.unsqueeze(1), src=torch.tensor(0))\n",
    "        \n",
    "        node_type_stack = torch.stack([node_type]*len(type_order)).t()\n",
    "        \n",
    "        # Process 2\n",
    "        back_vector += context_matrix.gather(dim=2, index=node_type_stack.unsqueeze(2)).squeeze(2)\n",
    "        context_matrix.scatter_(dim=2, index=node_type_stack.unsqueeze(2), src=torch.tensor(0))\n",
    "        go_vector.scatter_(dim=1, index=node_type.unsqueeze(1), src=torch.tensor(0))\n",
    "        \n",
    "        # Process 3\n",
    "        src = torch.stack([A]*v.shape[0]).gather(dim=1, index=node_type_stack.unsqueeze(1))\n",
    "        context_matrix.scatter_add_(dim=1, index=node_type_stack.unsqueeze(1), src=src)\n",
    "        go_vector += src.squeeze(1)\n",
    "        \n",
    "        # Process 4\n",
    "        weight = go_vector + back_vector\n",
    "        np.set_printoptions(precision=10000, suppress=False)\n",
    "        weight = weight * (adj_size[node] > 0).float()\n",
    "        node_type = torch.multinomial(weight, 1).squeeze(1)\n",
    "        \n",
    "        adj_size_type = adj_size[node].gather(dim=1, index=node_type.unsqueeze(1)).squeeze(1)\n",
    "        assert not torch.any(adj_size_type == 0)\n",
    "        \n",
    "        offset = torch.floor(torch.rand_like(node, dtype=torch.float) * adj_size_type).long()\n",
    "        \n",
    "        adj_start_type = adj_start[node].gather(dim=1, index=node_type.unsqueeze(1)).squeeze(1)\n",
    "        idx = adj_start_type + offset\n",
    "        \n",
    "        node = adj_data[idx]\n",
    "        walk[i] = node\n",
    "    return torch.stack(walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A = torch.randint(1, 3, size=(4, 4)).float()\n",
    "A = torch.tensor([[1, 10000, 1, 1], [10000, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]).float()\n",
    "node = torch.randint(80000, size=(1,), dtype=torch.long)\n",
    "node_type = torch.tensor([get_type(x, data['type_interval'], type_order) for x in node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit walk = balancewalk(node, node_type, 100, A, len(type_order), adj_data, adj_size, adj_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk = balancewalk(node, node_type, 100, A, len(type_order), adj_data, adj_size, adj_start)\n",
    "print((torch.tensor([[get_type(x, data['type_interval'], type_order) for x in b] for b in walk])==0).nonzero().shape[0],\n",
    "(torch.tensor([[get_type(x, data['type_interval'], type_order) for x in b] for b in walk])==1).nonzero().shape[0],\n",
    "(torch.tensor([[get_type(x, data['type_interval'], type_order) for x in b] for b in walk])==2).nonzero().shape[0],\n",
    "(torch.tensor([[get_type(x, data['type_interval'], type_order) for x in b] for b in walk])==3).nonzero().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([[get_type(x, data['type_interval'], type_order) for x in b] for b in walk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['class']['T'] = np.full(data['type_interval']['T'][1]-data['type_interval']['T'][0]+1, fill_value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = np.concatenate((data['class']['A'], data['class']['T'], data['class']['V'], data['class']['P']), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_list(walk, key):\n",
    "    walk = [x for x in walk if data['type_interval'][key][0]<=x and x<=data['type_interval'][key][1]]\n",
    "    return [class_dict[x] for x in walk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_class_list(walk, 'V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_str_dict = {x: i for i, x in enumerate(data['type_interval'].keys())}\n",
    "type_str_inverse_dict = {i: x for x, i in type_str_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_type_mask = torch.zeros(len(data['adj_indice'].keys()), 4)\n",
    "for k, v in data['adj_indice'].items():\n",
    "    for k2 in v.keys():\n",
    "        possible_type_mask[k, type_str_dict[k2]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacent_node_num_per_type = torch.zeros(data['node_num'], 4, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in data['adj_indice'].items():\n",
    "    for k2, v2 in v.items():\n",
    "        adjacent_node_num_per_type[k, type_str_dict[k2]] = len(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacent_node_num_per_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = torch.zeros(data['node_num'], 4, dtype=torch.long)\n",
    "tmp = torch.zeros(4, dtype=torch.long)\n",
    "for i in range(data['node_num']):\n",
    "    start_idx[i, :] = tmp\n",
    "    tmp += adjacent_node_num_per_type[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_adj = [None] * 4\n",
    "for type_k, type_idx in type_str_dict.items():\n",
    "    packed_adj[type_idx] = [None] * data['node_num']\n",
    "    for k, v in data['adj_indice'].items():\n",
    "        packed_adj[type_idx][k] = torch.tensor(list(v[type_k]) if v.get(type_k) is not None else [], dtype=torch.long)\n",
    "    packed_adj[type_idx] = torch.cat(packed_adj[type_idx], dim=0)\n",
    "pad_packed_adj = nn.utils.rnn.pad_sequence(packed_adj)\n",
    "print(pad_packed_adj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get(pad_packed_adj, start_idx, adjacent_node_num_per_type, node, idx, type_):\n",
    "    return pad_packed_adj[start_idx[node, type_]+idx, type_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get(pad_packed_adj, \n",
    "    start_idx, \n",
    "    adjacent_node_num_per_type, \n",
    "    torch.tensor([19999, 20000], dtype=torch.long), \n",
    "    torch.tensor([0, 0], dtype=torch.long), \n",
    "    torch.tensor([3, 1], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_attention = torch.from_numpy(np.asarray([[1, 1, 1, 1], [1, 1, 1, 1], [100, 1, 1, 1], [1, 1, 1, 1]])).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_packed_adj = pad_packed_adj.cuda()\n",
    "start_idx = start_idx.cuda()\n",
    "adjacent_node_num_per_type = adjacent_node_num_per_type.cuda()\n",
    "possible_type_mask = possible_type_mask.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class BalancedWalkFactory(object):\n",
    "    def __init__(self,\n",
    "                 possible_type_mask,\n",
    "                 adjacent_node_num_per_type,\n",
    "                 start_idx,\n",
    "                 pad_packed_adj,\n",
    "                 type_attention,\n",
    "                 type_str_dict):\n",
    "        self.possible_type_mask = possible_type_mask\n",
    "        self.adjacent_node_num_per_type = adjacent_node_num_per_type\n",
    "        self.start_idx = start_idx\n",
    "        self.pad_packed_adj = pad_packed_adj\n",
    "        self.type_attention = type_attention\n",
    "        self.type_str_dict = type_str_dict\n",
    "    \n",
    "    def to(self, device):\n",
    "        self.possible_type_mask = self.possible_type_mask.to(device)\n",
    "        self.adjacent_node_num_per_type = self.adjacent_node_num_per_type.to(device)\n",
    "        self.start_idx = self.start_idx.to(device)\n",
    "        self.pad_packed_adj = self.pad_packed_adj.to(device)\n",
    "        self.type_attention = self.type_attention.to(device)\n",
    "        return self\n",
    "        \n",
    "    def __call__(self, v, l):\n",
    "        batch_size = v.shape[0]\n",
    "        walk = v.new_zeros(l, batch_size, dtype=torch.long)\n",
    "        walk[0, :] = v\n",
    "\n",
    "        history = v.new_zeros(l, batch_size, 4, dtype=torch.long)\n",
    "        return_history = v.new_full((l, batch_size), fill_value=-1, dtype=torch.long)\n",
    "        to_prob = v.new_zeros(batch_size, 4, dtype=torch.long)\n",
    "\n",
    "        cur_type = v.new_tensor([self.type_str_dict[get_type(x, data['type_interval'])] for x in walk[0, :]], dtype=torch.long)\n",
    "\n",
    "        for i in range(1, l):\n",
    "            history[i-1, :, :] = type_attention[cur_type]\n",
    "            return_history[i-1, :] = cur_type\n",
    "            prob = history.sum(dim=0)\n",
    "            prob += to_prob\n",
    "            prob *= possible_type_mask[walk[i-1,:]].long()\n",
    "    \n",
    "            nxt_type = torch.multinomial(prob.float(), 1)\n",
    "            idx = torch.rand(batch_size).cuda()\n",
    "            size = torch.gather(adjacent_node_num_per_type[walk[i-1,:]], 1, nxt_type).squeeze()\n",
    "    \n",
    "            idx = torch.floor(idx * size.float()).long()\n",
    "    \n",
    "            walk[i, :] = get(pad_packed_adj, \n",
    "                             start_idx, \n",
    "                             adjacent_node_num_per_type, \n",
    "                             walk[i-1, :], \n",
    "                             idx, \n",
    "                             nxt_type.squeeze())\n",
    "            cur_type = nxt_type.squeeze()\n",
    "        \n",
    "            to_prob.scatter_(dim=1, index=nxt_type, src=torch.tensor(0))\n",
    "            for j in range(i):\n",
    "                to_prob.scatter_add_(dim=1, index=return_history[[j], :].t(), \n",
    "                                 src=torch.gather(history[j, :, :], dim=1, index=nxt_type))\n",
    "                history[j, :, :].scatter_(dim=1, index=nxt_type, src=torch.tensor(0))\n",
    "        return walk\n",
    "\n",
    "balanced_walk = BalancedWalkFactory(possible_type_mask,\n",
    "                                    adjacent_node_num_per_type,\n",
    "                                    start_idx,\n",
    "                                    pad_packed_adj,\n",
    "                                    torch.from_numpy(np.asarray([[1, 1, 1, 1], [1, 1, 1, 1], [100, 1, 1, 1], [1, 1, 1, 1]])),\n",
    "                                    type_str_dict)\n",
    "balanced_walk = balanced_walk.to(torch.device(\"cuda:0\"))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(5):\n",
    "    walk = balanced_walk(torch.arange(0, 100, 1).cuda(), 80)\n",
    "\n",
    "print('--- %s seconds ---' % (time.time() - start_time))\n",
    "print(walk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_walk(v, adj, type_interval, type_str_dict, type_str_inverse_dict, type_, l): \n",
    "    walk = [v] * l \n",
    "    from_que = deque()\n",
    "    to_prob = np.asarray([0] * 4)\n",
    "    for i in range(1, l): \n",
    "        cur_type = type_str_dict[get_type(walk[i-1], type_interval)]\n",
    "        possible_type = list(map(type_str_dict.get, adj[walk[i-1]].keys()))\n",
    "\n",
    "        # From que update\n",
    "        from_que.append((cur_type, np.copy(type_[cur_type])))\n",
    "\n",
    "        # Calculate probability\n",
    "        prob = np.asarray([0] * 4, dtype=np.float32)\n",
    "        for _, p in from_que:\n",
    "            prob += p\n",
    "        prob += to_prob\n",
    "\n",
    "        nxt_type = np.random.choice(possible_type, 1, p=prob[possible_type]/prob[possible_type].sum())[0]\n",
    "        walk[i] = np.random.choice(list(adj[walk[i-1]][type_str_inverse_dict[nxt_type]]), 1)[0]\n",
    "\n",
    "        # To prob update\n",
    "        to_prob[nxt_type] = 0 \n",
    "        for return_type, p in from_que:\n",
    "            to_prob[return_type] += p[nxt_type]\n",
    "            p[nxt_type] = 0 \n",
    "\n",
    "        while len(from_que) > 0:\n",
    "            if np.all(from_que[0]==0):\n",
    "                from_que.popleft()\n",
    "            else:\n",
    "                break\n",
    "    return walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk = walk.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df_list = []\n",
    "\n",
    "for i in range(1000):\n",
    "    walk = balanced_walk(1, \n",
    "                     data['adj_indice'], \n",
    "                     data['type_interval'], \n",
    "                     type_str_dict,\n",
    "                         type_str_inverse_dict,\n",
    "                     np.asarray([[1, 1, 1, 1], [1, 1, 1, 1], [100, 1, 1, 1], [1, 1, 1, 1]]), \n",
    "                     40)\n",
    "    df = pd.DataFrame({'walk': walk, 'class': [class_dict[x] for x in walk], 'type': [get_type(x, data['type_interval']) for x in walk]})\n",
    "    count_df_list.append(df.groupby('type').count())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#walk = walk[:, 0].cpu().numpy()\n",
    "df = pd.DataFrame({'walk': walk, 'class': [class_dict[x] for x in walk], 'type': [get_type(x, data['type_interval']) for x in walk]})\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df_list = []\n",
    "count_df_list.append(df.groupby('type').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(count_df_list).groupby('type').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['type']=='P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
